{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIAkIlfmCe1B"
   },
   "source": [
    "# The Hello World of Neural Networks with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVSfnRuezLQ7"
   },
   "source": [
    "The provided code demonstrates the entire process of creating a simple linear regression model, training it, making predictions, and inspecting the model's parameters. The dataset used consists of a set of numbers x and y, where x is `[-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]`, and y is `[-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]`. The model's objective is to approximate the linear relationship `y = 2x - 1` based on this training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:40.398004Z",
     "start_time": "2025-12-10T02:12:39.895813Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pynvml\n",
    "%pip install nvidia-ml-py\n",
    "%pip install torchinfo  # Reemplaza torchsummary, compatible con MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:42.969412Z",
     "start_time": "2025-12-10T02:12:42.954443Z"
    },
    "id": "6nUiRW8zhVLe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is  [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
      "y is  [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"x is \", [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]) #input\n",
    "print(\"y is \", [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]) #output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brdnVSvRhMPJ"
   },
   "source": [
    "\n",
    "\n",
    "Note that with a rule-based approach, we should only write a function like this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:44.473659Z",
     "start_time": "2025-12-10T02:12:44.454182Z"
    },
    "id": "6mHvaGEchOaW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For x = 4 , y =  7\n"
     ]
    }
   ],
   "source": [
    "def function_with_rules(x):\n",
    "    y = (2 * x) - 1\n",
    "    return y\n",
    "\n",
    "x = 4\n",
    "print(\"For x =\", x, \", y = \", function_with_rules(x=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzbtdRcZDO9B"
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We import the necessary libraries, including PyTorch for building and training the neural network model and NumPy for handling numerical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:47.073486Z",
     "start_time": "2025-12-10T02:12:46.579754Z"
    },
    "id": "X9uIpOS2zx7k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #neural nets\n",
    "import torch.optim as optim #\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUG6PYDYcHbq"
   },
   "source": [
    "# Check for GPU availability\n",
    "\n",
    "This line of code initializes a PyTorch device based on whether CUDA, the GPU acceleration library for NVIDIA GPUs, is available on the system or not. So, the line of code essentially sets the device variable to \"cuda\" if CUDA is available, indicating that GPU acceleration can be used, and \"cpu\" otherwise, indicating that computations should be performed on the CPU. This approach allows for seamless switching between CPU and GPU computations based on availability, ensuring that the code runs on the best available hardware without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:50.191279Z",
     "start_time": "2025-12-10T02:12:50.162164Z"
    },
    "id": "bL-xBxq0b_JB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"You are using\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS_M1P5ljJyH"
   },
   "source": [
    "## Inspecting GPU Status in Google Colab\n",
    "When you run !nvidia-smi, it displays information about the Nvidia GPU allocated to your Colab session, including details such as the GPU model, GPU memory usage, processes currently running on the GPU, and more. This command is useful for verifying that you have access to a GPU and for monitoring GPU usage during training or inference tasks in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4Oj-S3Hicka"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi #only works for device = \"gpu\"!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aeu39Rf2paZ1"
   },
   "source": [
    "The command `nvidia-smi -L `lists the available GPUs on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U7njDbpoykG"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi  -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssx3QpOdpF1p"
   },
   "source": [
    "The command `nvidia-smi -L | wc -l` is used to count the number of GPUs available on a machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEeO2OG7pAeP"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi  -L | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLycFE1Wq0hD"
   },
   "source": [
    "## Controlling GPU Allocation with CUDA_VISIBLE_DEVICES Configuration\n",
    "This code snippet sets the environment variable CUDA_VISIBLE_DEVICES, which is used by CUDA (NVIDIA's parallel computing platform) to specify which GPUs should be made visible to CUDA-enabled applications.\n",
    "\n",
    "Setting CUDA_VISIBLE_DEVICES is useful when you have multiple GPUs available but only want to use a subset of them for a specific task. By setting this environment variable, you can control which GPUs are utilized by CUDA-enabled applications, such as deep learning frameworks like TensorFlow or PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:53.173102Z",
     "start_time": "2025-12-10T02:12:53.152390Z"
    },
    "id": "tzstg0hAqBuc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando MPS (Metal Performance Shaders) - GPU de Apple Silicon\n",
      "MPS utiliza automáticamente la GPU integrada del chip Apple\n"
     ]
    }
   ],
   "source": [
    "# Para MPS (Apple Silicon), no hay necesidad de configurar dispositivos visibles\n",
    "# ya que solo hay una GPU integrada\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    print(\"Usando MPS (Metal Performance Shaders) - GPU de Apple Silicon\")\n",
    "    print(\"MPS utiliza automáticamente la GPU integrada del chip Apple\")\n",
    "elif device.type == \"cuda\":\n",
    "    num_gpus = 1  # num. gpus you want to use in this notebook\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(str(x) for x in range(num_gpus))\n",
    "    print(\"CUDA_VISIBLE_DEVICES =\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "else:\n",
    "    print(\"Usando CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecc24661"
   },
   "source": [
    "## Function to Select the Best CUDA Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc31ea1c"
   },
   "source": [
    "This function `get_best_cuda_device` helps in automatically selecting the most suitable CUDA-enabled GPU device for PyTorch computations. It checks for CUDA availability and, if multiple GPUs are present, it identifies the one with the most free memory to optimize performance and avoid out-of-memory errors. If no CUDA device is available, it defaults to using the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T02:12:55.485578Z",
     "start_time": "2025-12-10T02:12:55.374072Z"
    },
    "id": "Kn7y05Z9X0pK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal Performance Shaders) está disponible.\n",
      "Usando GPU de Apple Silicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versión adaptada para MPS, CUDA y CPU\n",
    "import torch\n",
    "\n",
    "def get_best_device():\n",
    "    \"\"\"\n",
    "    Selecciona el mejor dispositivo disponible:\n",
    "    - MPS (Metal Performance Shaders) para Apple Silicon\n",
    "    - CUDA para GPUs NVIDIA\n",
    "    - CPU como fallback\n",
    "    \"\"\"\n",
    "    # Verificar MPS (Apple Silicon)\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS (Metal Performance Shaders) está disponible.\")\n",
    "        print(\"Usando GPU de Apple Silicon\")\n",
    "        return torch.device(\"mps\")\n",
    "    \n",
    "    # Verificar CUDA (NVIDIA GPUs)\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            import pynvml\n",
    "            pynvml.nvmlInit()\n",
    "            best_gpu = 0\n",
    "            max_free_mem = 0\n",
    "\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                free_mem = mem_info.free\n",
    "                print(f\"GPU {i} - Memoria libre: {free_mem / 1024**2:.2f} MiB\")\n",
    "\n",
    "                if free_mem > max_free_mem:\n",
    "                    best_gpu = i\n",
    "                    max_free_mem = free_mem\n",
    "\n",
    "            pynvml.nvmlShutdown()\n",
    "            print(f\"Seleccionando GPU {best_gpu} con más memoria libre.\")\n",
    "            return torch.device(f\"cuda:{best_gpu}\")\n",
    "        except:\n",
    "            print(\"CUDA disponible pero error al obtener información de memoria.\")\n",
    "            return torch.device(\"cuda\")\n",
    "    \n",
    "    # Fallback a CPU\n",
    "    print(\"GPU no disponible. Usando CPU.\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "get_best_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oql3J_hY1EP-"
   },
   "source": [
    "# Model Definition\n",
    "We define a simple linear regression model using PyTorch's `nn.Sequential` container. Inside the container, we have one `nn.Linear` layer, which represents a linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "djDO-7Kl1Qu4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a simple Sequential model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 1) # theta'*x, logits\n",
    "    #no activation\n",
    ")\n",
    "\n",
    "model.to(device)# Move the model to the GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o91Cgx2X1SrY"
   },
   "source": [
    "This code defines a simple neural network model using PyTorch's `nn.Sequential` container, which is a convenient way to create a sequence of neural network layers. In this case, we have only one layer:\n",
    "\n",
    "* `nn.Linear(1, 1)`: This line defines a linear (fully connected) layer within the model. Let's break down the arguments:\n",
    "\n",
    "    * `nn.Linear`: This is the linear layer class provided by PyTorch, which implements a linear transformation. It's essentially a matrix multiplication operation.\n",
    "\n",
    "    * `1, 1`: The first 1 represents the number of input features, and the second 1 represents the number of output features. In other words, this layer has one input feature and produces one output feature.\n",
    "\n",
    "So, what does this layer do? It's a linear transformation that can be expressed as $y=\\theta_0+\\theta_1x$ , where:\n",
    "\n",
    "* $y$ is the output (a single number in this case).\n",
    "* $\\theta_1$ is the weight (a learnable parameter), and since it's 1x1, it's a scalar.\n",
    "* $x$ is the input feature (a single number in this case).\n",
    "* $\\theta_0$ is the bias (another learnable parameter), also a scalar.\n",
    "\n",
    "This linear layer essentially tries to learn the best values for $\\theta_0$  and $\\theta_1$  that allow the model to make predictions based on the input feature $x$.\n",
    "\n",
    "In the context of this linear regression problem (predicting y based on x), this linear layer models a linear relationship between x and y. It's the core of this model, and its goal during training is to adjust the weights $\\theta_0$  and $\\theta_1$ to minimize the mean squared error (MSE) between the predicted values and the actual target values.\n",
    "\n",
    "The `.to(device)` method in PyTorch is used to move tensors or models to a specific device, such as a GPU or CPU. This method is commonly used to ensure that the tensors and models are compatible with the device on which computations are performed.\n",
    "\n",
    "When you call .to(device), you specify the device as an argument. For example, if you want to move a tensor or model to the GPU (if available), you use torch.device(\"cuda\"). If you want to use the CPU, you specify torch.device(\"cpu\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxuKXMiFfINP"
   },
   "source": [
    "## Visualizing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZM2KxJuhfLCL"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# our input is a single feature\u001b[39;00m\n\u001b[1;32m      3\u001b[0m summary(model, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, features))  \u001b[38;5;66;03m# (batch_size, features)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "features = 1  # our input is a single feature\n",
    "summary(model, input_size=(1, features))  # (batch_size, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS9PBIwLfX3c"
   },
   "source": [
    "The provided code snippet utilizes the summary function from the `torchsummary` library to generate a summary of the model, including information about the layers and their output shapes.\n",
    "\n",
    "Here's a breakdown of each part of the code:\n",
    "\n",
    "`from torchsummary import summary:` This line imports the summary function from the `torchsummary` library. This function provides a summary of a PyTorch model, including details such as the number of parameters and the output shapes of each layer.\n",
    "\n",
    "`features = 1: `This line defines the number of features in the input data. In this case, it indicates that the input to the model consists of a single feature. This information is used to specify the input size when generating the model summary.\n",
    "\n",
    "`summary(model, input_size=(features,)):` This line calls the summary function, passing in the model and the input size as arguments. The input_size parameter specifies the size of the input data expected by the model. In this case, it is specified as a tuple `(features,)`, indicating that the input data consists of a single feature. The summary function then analyzes the model and generates a summary, including details such as the layer types, output shapes, and the number of parameters in each layer.\n",
    "\n",
    "The output shape [-1,1] indicates that the output of the model has a batch dimension (-1) and a single feature dimension (1). The -1 in the batch dimension represents that the batch size can vary and is determined dynamically based on the input data during inference or training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcL6WAvZ53Uk"
   },
   "source": [
    "\n",
    "# Loss Function and Optimizer\n",
    "\n",
    "We define the loss function as Mean Squared Error (MSE) using `nn.MSELoss`. This is a common loss function for regression problems.\n",
    "We then set up the optimizer as Stochastic Gradient Descent (SGD) using `optim.SGD`. It's used to update the model's parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aRXrzYOL6De_"
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss() #evaluation, loss function J\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t51Z9dkG6usr"
   },
   "source": [
    " Let's break down the code where the loss function and optimizer are defined:\n",
    "\n",
    "* `criterion = nn.MSELoss()`: Here, we define the loss function as Mean Squared Error (MSE) using `nn.MSELoss()`. The `MSELoss` measures the mean squared difference between predicted values and actual target values. In the context of linear regression, it quantifies how well the model's predictions match the true target values. The goal during training is to minimize this loss, meaning the model aims to make its predictions as close as possible to the actual targets.\n",
    "\n",
    "* `optimizer = optim.SGD(model.parameters(), lr=0.01)`: We define the optimizer as Stochastic Gradient Descent (SGD) using `optim.SGD`. The parameters of this optimizer are as follows:\n",
    "    * `model.parameters()`: This method retrieves all the learnable parameters of the model. In the context of the linear regression model, these parameters are the weights  $\\theta_0$  and $\\theta_1$   of the linear layer defined earlier. The optimizer will adjust these parameters during training to minimize the loss.\n",
    "    * `lr=0.01`: This sets the learning rate for the optimizer. The learning rate is a hyperparameter that controls the step size during the optimization process. It influences how quickly or slowly the model's parameters are updated. A smaller learning rate makes the training more stable but may require more epochs to converge, while a larger learning rate can speed up convergence but may lead to overshooting the optimal parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPRo7Hz0hiLy"
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "We define our input data `xs` and output data `ys` as NumPy arrays. `xs` contains the input values, and `ys` contains the corresponding target values.\n",
    "\n",
    "We convert these NumPy arrays into PyTorch tensors and reshape them using view to ensure they have the correct shape for PyTorch.\n",
    "\n",
    "`.view(-1, 1)` is used to reshape the tensors. The -1 in the view method indicates that the size of that dimension is inferred from the length of the data in the tensor, and 1 specifies the new shape. In this case, it reshapes the tensors to have dimensions `(6, 1)`, where 6 represents the number of data points, and 1 represents that there is one feature for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-HJpQqWqiB9h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "# Declare model inputs and outputs for training y = 2x - 1\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=np.float32)\n",
    "\n",
    "print(xs.shape)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors and reshape xs and move to the GPU if available\n",
    "xs = torch.tensor(xs).view(-1, 1).to(device)\n",
    "ys = torch.tensor(ys).view(-1, 1).to(device)\n",
    "\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-1uErzfis6l"
   },
   "source": [
    "This code prepares data for training a model using PyTorch by creating a dataset and a data loader. The dataset contains input-output pairs (`xs` and `ys`), and the data loader will provide batches of this data for training, with each batch containing a specified number of samples (`batch_size`) and being shuffled for each epoch (`shuffle=True`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKM3-4gXjh2P"
   },
   "source": [
    "Let's break down what each part of the code does:\n",
    "\n",
    "1. `from torch.utils.data import TensorDataset, DataLoader`: This line imports the `TensorDataset` class and the `DataLoader` class from the `torch.utils.data` module. These classes are commonly used in PyTorch for handling datasets and data loading during the training process.\n",
    "\n",
    "2. `dataset = TensorDataset(xs, ys)`: This line creates a dataset object using the `TensorDataset` class. `xs` and `ys` are tensors containing input data and corresponding labels, respectively. The `TensorDataset` class allows you to combine these input-output pairs into a single dataset object.\n",
    "\n",
    "3. `dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)`: This line creates a data loader object using the `DataLoader` class. It takes the dataset object created earlier (`dataset`) and additional parameters like `batch_size` and `shuffle`. Here, `batch_size` specifies the number of samples per batch, and `shuffle=True` indicates that the data will be shuffled randomly before being divided into batches. The data loader will then iterate over these batches during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "p1V4l5MjSPlf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs:  tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.]], device='mps:0') \n",
      "ys:  tensor([[-3.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [ 3.],\n",
      "        [ 5.],\n",
      "        [ 7.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Create dataset\n",
    "dataset = TensorDataset(xs, ys)\n",
    "print(\"xs: \", dataset.tensors[0], \"\\nys: \", dataset.tensors[1])\n",
    "\n",
    "#reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT7Cu9kb-ZIX"
   },
   "source": [
    "# Example of Automatic Differentiation in PyTorch\n",
    "\n",
    "This code demonstrates a fundamental concept in PyTorch: automatic differentiation using the .backward() method. It shows how to define a simple mathematical function, mark a tensor for which you want to compute gradients, and then automatically calculate the derivative of the function with respect to that tensor. This is the core mechanism that enables training neural networks by calculating the gradients of the loss function with respect to the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6jqN7Efn9KnL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([14.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define a tensor x with requires_grad=True to track gradients\n",
    "x = torch.tensor([7.0], requires_grad=True)\n",
    "\n",
    "# Define the function y = x^2\n",
    "y = x**2\n",
    "\n",
    "print(x.grad) #None before backward\n",
    "\n",
    "# Compute the gradients of y with respect to x\n",
    "y.backward() # the gradient is 2*x\n",
    "\n",
    "# Print the gradient of x\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRRWifWmV5ym"
   },
   "source": [
    "#**Training**\n",
    "\n",
    "This code represents a typical training loop for a neural network model using PyTorch. Let's break it down step by step:\n",
    "\n",
    "1. **Training Loop Initialization**: It sets the number of epochs (`num_epochs`) to 500, indicating how many times the entire dataset will be passed forward and backward through the neural network.\n",
    "\n",
    "2. **Loop Over Epochs**: The outer loop iterates over each epoch from 0 to `num_epochs - 1`. During each epoch, the entire dataset is passed through the network once.\n",
    "\n",
    "3. **Inner Loop Over Batches**: The inner loop iterates over batches of data (`xs_batch` and `y_batch`) obtained from the `dataloader`. `xs_batch` contains input data samples, and `y_batch` contains corresponding labels.\n",
    "\n",
    "4. **Forward Pass**: Inside the inner loop, the input batch (`xs_batch`) is fed into the neural network model (`model`) to obtain predictions (`outputs`).\n",
    "\n",
    "5. **Compute Loss**: The predicted outputs (`outputs`) are compared against the actual labels (`y_batch`) using a loss function (`criterion`) to calculate the loss value (`loss`). The loss quantifies how well the model's predictions match the true labels.\n",
    "\n",
    "6. **Backpropagation and Parameter Update**: We clear the gradients using `optimizer.zero_grad()` to prepare for a new backward pass. This is essential to avoid the accumulation of gradients from one batch to the next, which could lead to incorrect and unstable training. It's a standard practice when training neural networks with gradient-based optimization algorithms like stochastic gradient descent (SGD).\n",
    "After computing the loss, the gradients of the model parameters with respect to the loss are calculated (`loss.backward()`), and the optimizer updates the model parameters based on these gradients (`optimizer.step()`). This process is called backpropagation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "T5gNEbGclwl_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================, End of Epoch 0\n",
      "At Epoch  0 Loss is 0.4724831283092499\n",
      "======================, End of Epoch 1\n",
      "======================, End of Epoch 2\n",
      "======================, End of Epoch 3\n",
      "======================, End of Epoch 4\n",
      "======================, End of Epoch 5\n",
      "At Epoch  5 Loss is 1.500733494758606\n",
      "======================, End of Epoch 6\n",
      "======================, End of Epoch 7\n",
      "======================, End of Epoch 8\n",
      "======================, End of Epoch 9\n",
      "======================, End of Epoch 10\n",
      "At Epoch  10 Loss is 2.4987146854400635\n",
      "======================, End of Epoch 11\n",
      "======================, End of Epoch 12\n",
      "======================, End of Epoch 13\n",
      "======================, End of Epoch 14\n",
      "======================, End of Epoch 15\n",
      "At Epoch  15 Loss is 1.4497300386428833\n",
      "======================, End of Epoch 16\n",
      "======================, End of Epoch 17\n",
      "======================, End of Epoch 18\n",
      "======================, End of Epoch 19\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (xs_batch, y_batch) in enumerate(dataloader):\n",
    "\n",
    "        #print(\"Batch\", batch_idx, \"xs_batch:\", xs_batch, \"\\nys_batch:\", y_batch)\n",
    "        #print(\"***************\")\n",
    "        # Forward pass\n",
    "        outputs = model(xs_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, y_batch) #MSE\n",
    "\n",
    "        # Zero the gradients, perform a backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer.step() #Gradiend descent\n",
    "\n",
    "    print(\"======================, End of Epoch\", epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"At Epoch \", epoch, \"Loss is\", loss.item()) # Use loss.item() to get a scalar value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRFiBKblUB8K"
   },
   "source": [
    "# Making a Prediction:\n",
    "After training, we make a prediction for the input value 10.0 by passing it through the trained model and converting the result to a Python scalar using `.item()`. The statement  `with torch.no_grad()` disables gradient calculation for the operations inside the with block. Gradient calculation is used during training to update the model's parameters. However, when making predictions, we don't need to calculate gradients.\n",
    "\n",
    "Forgetting to set the PyTorch model to evaluation mode (model.eval()) before performing inference can lead to unexpected behavior, particularly with layers like Batch Normalization or Dropout, which behave differently during training and inference. This can result in incorrect predictions or degraded model performance due to improper normalization or dropout. It's best practice to always set the model to evaluation mode before inference to ensure consistent behavior and accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "6i2wI_9fTwCs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16.5392], device='mps:0')\n",
      "16.53920555114746\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_value = model(torch.tensor([10.0]).to(device))\n",
    "\n",
    "print(predicted_value)\n",
    "print(predicted_value.item())  # Convert the result to a Python scalar\n",
    "\n",
    "#y = 2*x - 1 para x = 10: y:19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC1AGQhbUQBO"
   },
   "source": [
    "# Printing Model Parameters\n",
    "Finally, we print the model's parameter names and their values. In this case, there's only one set of parameters corresponding to the linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "huxPjczLTx1s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "tensor([[1.6427]], device='mps:0')\n",
      "0.bias\n",
      "tensor([0.1123], device='mps:0')\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print model layer information\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.data)# print(param.data.item())\n",
    "    #print(param.grad)\n",
    "print(model)\n",
    "\n",
    "# y = 2*x -1 = theta_0 + theta_1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGLSRktq5RKi"
   },
   "source": [
    "# Actividad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM6qyDOYOfmn"
   },
   "source": [
    "For the given data, build a neural network with two hidden layers, each consisting of 'N' units, and use the sigmoid activation function. Choose the value of 'N' so that the prediction for an input of 2.5 is as close as possible to the expected value (considering the quadratic relationship between the input and output). The output layer should have a single unit with a linear activation function. Compile your model using the same optimizer and loss function as in the previous example. Train your model for 10000 epochs and calculate the mean squared error (MSE) on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "efZJ9q7N6Xf5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Declare model inputs and outputs for training y = x^2\n",
    "xs = np.array([-4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "ys = np.array([16, 9, 4, 1, 0, 1, 4, 9, 16], dtype=np.float32)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "xs = torch.tensor(xs).view(-1, 1)\n",
    "ys = torch.tensor(ys).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Move tensors to the appropriate device\n",
    "xs = xs.to(device)\n",
    "ys = ys.to(device)\n",
    "\n",
    "# Define N (number of neurons per hidden layer)\n",
    "N = 8  # This value can be tuned for better performance\n",
    "\n",
    "# Build a neural network with two hidden layers with sigmoid activation\n",
    "model_quadratic = nn.Sequential(\n",
    "    nn.Linear(1, N),      # Input layer to first hidden layer\n",
    "    nn.Sigmoid(),         # Sigmoid activation\n",
    "    nn.Linear(N, N),      # First hidden layer to second hidden layer\n",
    "    nn.Sigmoid(),         # Sigmoid activation\n",
    "    nn.Linear(N, 1)       # Second hidden layer to output (linear activation)\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model_quadratic.to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model_quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Parameters (after training):\n",
      "==================================================\n",
      "\n",
      "0.weight:\n",
      "tensor([[-0.5164],\n",
      "        [-0.6817],\n",
      "        [ 0.5306],\n",
      "        [-0.4042],\n",
      "        [ 0.6069],\n",
      "        [-0.2373],\n",
      "        [ 0.5720],\n",
      "        [-0.7770]], device='mps:0')\n",
      "\n",
      "0.bias:\n",
      "tensor([-0.5046,  0.3049,  0.2114, -0.2550,  0.5961,  0.6798, -0.7252, -0.5339],\n",
      "       device='mps:0')\n",
      "\n",
      "2.weight:\n",
      "tensor([[ 0.3237, -0.1193, -0.1253, -0.3421, -0.2025,  0.0883, -0.0467, -0.2566],\n",
      "        [ 0.0083, -0.2415, -0.3000, -0.1947, -0.3094, -0.2251,  0.3534,  0.0668],\n",
      "        [ 0.1090, -0.3298, -0.2322, -0.1177,  0.0553, -0.3111, -0.1523, -0.2117],\n",
      "        [ 0.0010, -0.1316, -0.0245, -0.2396, -0.2427, -0.2063, -0.1210, -0.2791],\n",
      "        [ 0.2964, -0.0702,  0.3042,  0.1102, -0.2994,  0.2447, -0.0973, -0.1355],\n",
      "        [-0.2935, -0.3515,  0.1012, -0.0772,  0.1376, -0.2901,  0.2625, -0.2595],\n",
      "        [-0.0610,  0.0738,  0.1825,  0.2854,  0.3221, -0.2803,  0.0890, -0.1521],\n",
      "        [-0.0387, -0.2646,  0.3220, -0.2595,  0.1890,  0.1243,  0.1149, -0.1911]],\n",
      "       device='mps:0')\n",
      "\n",
      "2.bias:\n",
      "tensor([ 0.3214,  0.0777,  0.0455, -0.3116,  0.1484, -0.0530, -0.1620,  0.3037],\n",
      "       device='mps:0')\n",
      "\n",
      "4.weight:\n",
      "tensor([[ 0.0788, -0.1956, -0.1789, -0.0169,  0.1974, -0.0903, -0.2017, -0.1211]],\n",
      "       device='mps:0')\n",
      "\n",
      "4.bias:\n",
      "tensor([-0.2641], device='mps:0')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters\n",
    "print(\"\\nModel Parameters (after training):\")\n",
    "print(\"=\" * 50)\n",
    "for name, param in model_quadratic.named_parameters():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(param.data)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: MSE\n",
      "Optimizer: SGD with learning rate = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer (same as previous example)\n",
    "criterion_quadratic = nn.MSELoss()\n",
    "optimizer_quadratic = optim.SGD(model_quadratic.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Loss function: MSE\")\n",
    "print(\"Optimizer: SGD with learning rate = 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Mean Squared Error (MSE) on training dataset:\n",
      "==================================================\n",
      "MSE: 85.081932\n",
      "==================================================\n",
      "\n",
      "Predictions vs Actual Values:\n",
      "--------------------------------------------------\n",
      "       X  Predicted Y     Actual Y      Error\n",
      "--------------------------------------------------\n",
      "    -4.0      -0.4049         16.0    16.4049\n",
      "    -3.0      -0.4141          9.0     9.4141\n",
      "    -2.0      -0.4271          4.0     4.4271\n",
      "    -1.0      -0.4442          1.0     1.4442\n",
      "     0.0      -0.4641          0.0     0.4641\n",
      "     1.0      -0.4840          1.0     1.4840\n",
      "     2.0      -0.5014          4.0     4.5014\n",
      "     3.0      -0.5151          9.0     9.5151\n",
      "     4.0      -0.5254         16.0    16.5254\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Squared Error (MSE) on the training dataset\n",
    "model_quadratic.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_quadratic(xs)\n",
    "    mse = criterion_quadratic(predictions, ys)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Mean Squared Error (MSE) on training dataset:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"MSE: {mse.item():.6f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Show predictions vs actual values\n",
    "print(f\"\\nPredictions vs Actual Values:\")\n",
    "print(f\"{'-'*50}\")\n",
    "print(f\"{'X':>8} {'Predicted Y':>12} {'Actual Y':>12} {'Error':>10}\")\n",
    "print(f\"{'-'*50}\")\n",
    "for i in range(len(xs)):\n",
    "    x_val = xs[i].item()\n",
    "    pred_val = predictions[i].item()\n",
    "    actual_val = ys[i].item()\n",
    "    error = abs(pred_val - actual_val)\n",
    "    print(f\"{x_val:>8.1f} {pred_val:>12.4f} {actual_val:>12.1f} {error:>10.4f}\")\n",
    "print(f\"{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Prediction for x = 2.5:\n",
      "==================================================\n",
      "Predicted value: -0.5087\n",
      "Expected value:  6.2500\n",
      "Difference:      6.7587\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction for x = 2.5\n",
    "model_quadratic.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([2.5]).view(-1, 1).to(device)\n",
    "    predicted_value = model_quadratic(test_input)\n",
    "\n",
    "expected_value = 2.5 ** 2  # 6.25\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Prediction for x = 2.5:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Predicted value: {predicted_value.item():.4f}\")\n",
    "print(f\"Expected value:  {expected_value:.4f}\")\n",
    "print(f\"Difference:      {abs(predicted_value.item() - expected_value):.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/10000], Loss: 0.296147\n",
      "Epoch [2000/10000], Loss: 0.104834\n",
      "Epoch [3000/10000], Loss: 0.039529\n",
      "Epoch [4000/10000], Loss: 0.016563\n",
      "Epoch [5000/10000], Loss: 0.007931\n",
      "Epoch [6000/10000], Loss: 0.004488\n",
      "Epoch [7000/10000], Loss: 0.002975\n",
      "Epoch [8000/10000], Loss: 0.002211\n",
      "Epoch [9000/10000], Loss: 0.001760\n",
      "Epoch [10000/10000], Loss: 0.001454\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training loop for 10000 epochs\n",
    "num_epochs = 10000\n",
    "\n",
    "# Set model to training mode\n",
    "model_quadratic.train()\n",
    "\n",
    "# Track loss history\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model_quadratic(xs)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion_quadratic(outputs, ys)\n",
    "    \n",
    "    # Zero the gradients, perform a backward pass, and update the weights\n",
    "    optimizer_quadratic.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_quadratic.step()\n",
    "    \n",
    "    # Store loss\n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "    # Print progress every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1wSa-fOko9B"
   },
   "source": [
    "#References\n",
    "\n",
    "This code is inspired by the \"The Hello World of Neural Networks\" notebook from the TensorFlow Specialization by Deeplearning.ai. Concepts and implementations have been adapted for PyTorch."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1LWUC2qInMneIIu2JWSiEeRjLZfZ9sycu",
     "timestamp": 1765316077702
    },
    {
     "file_id": "1F7iWCGm1P5CNo9cbi3FG958doxLLviT7",
     "timestamp": 1697817221069
    },
    {
     "file_id": "1QQohj2pqqmdY-j2n0KbiG9BrHSmJp0pW",
     "timestamp": 1652993101787
    },
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/master/C1/W1/ungraded_lab/C1_W1_Lab_1_hello_world_nn.ipynb",
     "timestamp": 1652988664285
    },
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W1/ungraded_lab/C1_W1_Lab_1_hello_world_nn.ipynb",
     "timestamp": 1637670538744
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
