{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install nbconvert[pandoc]\n",
    "!apt-get update\n",
    "!apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
    "\n",
    "!jupyter nbconvert --to pdf planteamiento.ipynb"
   ],
   "metadata": {
    "collapsed": true,
    "id": "kpA31EvS7081",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:32:50.612368Z",
     "start_time": "2025-12-09T03:32:48.546003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: nbconvert[pandoc]\r\n",
      "zsh:1: command not found: apt-get\r\n",
      "zsh:1: command not found: apt-get\r\n",
      "[NbConvertApp] WARNING | pattern 'planteamiento.ipynb' matched no files\r\n",
      "This application is used to convert notebook files (*.ipynb)\r\n",
      "        to various other formats.\r\n",
      "\r\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\r\n",
      "\r\n",
      "Options\r\n",
      "=======\r\n",
      "The options below are convenience aliases to configurable class-options,\r\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\r\n",
      "To see all configurable class-options for some <cmd>, use:\r\n",
      "    <cmd> --help-all\r\n",
      "\r\n",
      "--debug\r\n",
      "    set log level to logging.DEBUG (maximize logging output)\r\n",
      "    Equivalent to: [--Application.log_level=10]\r\n",
      "--show-config\r\n",
      "    Show the application's configuration (human-readable format)\r\n",
      "    Equivalent to: [--Application.show_config=True]\r\n",
      "--show-config-json\r\n",
      "    Show the application's configuration (json format)\r\n",
      "    Equivalent to: [--Application.show_config_json=True]\r\n",
      "--generate-config\r\n",
      "    generate default config file\r\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\r\n",
      "-y\r\n",
      "    Answer yes to any questions instead of prompting.\r\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\r\n",
      "--execute\r\n",
      "    Execute the notebook prior to export.\r\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\r\n",
      "--allow-errors\r\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\r\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\r\n",
      "--stdin\r\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\r\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\r\n",
      "--stdout\r\n",
      "    Write notebook output to stdout instead of files.\r\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\r\n",
      "--inplace\r\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\r\n",
      "            relevant when converting to notebook format)\r\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\r\n",
      "--clear-output\r\n",
      "    Clear output of current file and save in place,\r\n",
      "            overwriting the existing notebook.\r\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\r\n",
      "--coalesce-streams\r\n",
      "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\r\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\r\n",
      "--no-prompt\r\n",
      "    Exclude input and output prompts from converted document.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\r\n",
      "--no-input\r\n",
      "    Exclude input cells and output prompts from converted document.\r\n",
      "            This mode is ideal for generating code-free reports.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\r\n",
      "--allow-chromium-download\r\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\r\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\r\n",
      "--disable-chromium-sandbox\r\n",
      "    Disable chromium security sandbox when converting to PDF..\r\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\r\n",
      "--show-input\r\n",
      "    Shows code input. This flag is only useful for dejavu users.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\r\n",
      "--embed-images\r\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\r\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\r\n",
      "--sanitize-html\r\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\r\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html=True]\r\n",
      "--log-level=<Enum>\r\n",
      "    Set the log level by value or name.\r\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\r\n",
      "    Default: 30\r\n",
      "    Equivalent to: [--Application.log_level]\r\n",
      "--config=<Unicode>\r\n",
      "    Full path of a config file.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--JupyterApp.config_file]\r\n",
      "--to=<Unicode>\r\n",
      "    The export format to be used, either one of the built-in formats\r\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\r\n",
      "            or a dotted object name that represents the import path for an\r\n",
      "            ``Exporter`` class\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--NbConvertApp.export_format]\r\n",
      "--template=<Unicode>\r\n",
      "    Name of the template to use\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--TemplateExporter.template_name]\r\n",
      "--template-file=<Unicode>\r\n",
      "    Name of the template file to use\r\n",
      "    Default: None\r\n",
      "    Equivalent to: [--TemplateExporter.template_file]\r\n",
      "--theme=<Unicode>\r\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\r\n",
      "    as prebuilt extension for the lab template)\r\n",
      "    Default: 'light'\r\n",
      "    Equivalent to: [--HTMLExporter.theme]\r\n",
      "--sanitize_html=<Bool>\r\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\r\n",
      "    should be set to True by nbviewer or similar tools.\r\n",
      "    Default: False\r\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html]\r\n",
      "--writer=<DottedObjectName>\r\n",
      "    Writer class used to write the\r\n",
      "                                        results of the conversion\r\n",
      "    Default: 'FilesWriter'\r\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\r\n",
      "--post=<DottedOrNone>\r\n",
      "    PostProcessor class used to write the\r\n",
      "                                        results of the conversion\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\r\n",
      "--output=<Unicode>\r\n",
      "    Overwrite base name use for output files.\r\n",
      "                Supports pattern replacements '{notebook_name}'.\r\n",
      "    Default: '{notebook_name}'\r\n",
      "    Equivalent to: [--NbConvertApp.output_base]\r\n",
      "--output-dir=<Unicode>\r\n",
      "    Directory to write output(s) to. Defaults\r\n",
      "                                  to output to the directory of each notebook. To recover\r\n",
      "                                  previous default behaviour (outputting to the current\r\n",
      "                                  working directory) use . as the flag value.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--FilesWriter.build_directory]\r\n",
      "--reveal-prefix=<Unicode>\r\n",
      "    The URL prefix for reveal.js (version 3.x).\r\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\r\n",
      "            of reveal.js.\r\n",
      "            For speaker notes to work, this must be a relative path to a local\r\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\r\n",
      "            If a relative path is given, it must be a subdirectory of the\r\n",
      "            current directory (from which the server is run).\r\n",
      "            See the usage documentation\r\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\r\n",
      "            for more details.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\r\n",
      "--nbformat=<Enum>\r\n",
      "    The nbformat version to write.\r\n",
      "            Use this to downgrade notebooks.\r\n",
      "    Choices: any of [1, 2, 3, 4]\r\n",
      "    Default: 4\r\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\r\n",
      "\r\n",
      "Examples\r\n",
      "--------\r\n",
      "\r\n",
      "    The simplest way to use nbconvert is\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\r\n",
      "\r\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\r\n",
      "\r\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\r\n",
      "\r\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\r\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\r\n",
      "            'classic'. You can specify the flavor of the format used.\r\n",
      "\r\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\r\n",
      "\r\n",
      "            You can also pipe the output to stdout, rather than a file\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\r\n",
      "\r\n",
      "            PDF is generated via latex\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\r\n",
      "\r\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\r\n",
      "\r\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\r\n",
      "\r\n",
      "            Multiple notebooks can be given at the command line in a couple of\r\n",
      "            different ways:\r\n",
      "\r\n",
      "            > jupyter nbconvert notebook*.ipynb\r\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\r\n",
      "\r\n",
      "            or you can specify the notebooks list in a config file, containing::\r\n",
      "\r\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\r\n",
      "\r\n",
      "            > jupyter nbconvert --config mycfg.py\r\n",
      "\r\n",
      "To see all available configurables, use `--help-all`.\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJGDTV5b7TCr"
   },
   "source": [
    "- Nombre: Jos茅 Obando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbXROubP8jBN"
   },
   "source": [
    "#  **Entregables**\n",
    "\n",
    "**No olvide duplicar esta notebook para poder editar: File->Save a copy in Drive**\n",
    "\n",
    "En este laboratorio, no es necesario redactar un informe en un documento separado. Por favor, complete todas las actividades requeridas dentro de esta notebook de Google Colab. Recuerde que una notebook le permite ingresar elementos de texto de manera similar a un procesador de documentos. Una vez finalizadas las actividades propuestas, deber谩 entregar lo siguiente en la plataforma:\n",
    "\n",
    "1. Un archivo PDF generado en Google Colab desde el men煤 \"Archivo\" -> \"Imprimir\".\n",
    "\n",
    "2. El enlace p煤blico de Google Colab. Para ello, vaya al bot贸n de compartir y cambie la configuraci贸n de compartici贸n a \"Cualquier persona con el enlace\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu3bmnB38mMf"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR56trFcPcC1"
   },
   "source": [
    "# Optimizaci贸n de hiperpar谩metros con PCA y sin PCA para la predicci贸n de p茅rdida de clientes en Empresas de Servicios de Telecomunicaciones (Churn) con regresi贸n log铆stica\n",
    "\n",
    "Reducir las salidas y [deserciones de clientes](https://www.bain.com/insights/breaking-the-back-of-customer-churn/) se ha convertido en una alta prioridad para la mayor铆a de los proveedores de servicios de comunicaciones a medida que los mercados maduran y la competencia se intensifica.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "En este documento usaremos una base de datos de una empresa de telecomunicaciones an贸nima [disponibilizada por IBM](https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv).\n",
    "\n",
    "El principal objetivo es crear un model de aprendizaje autom谩tico basado en Regresi贸n Log铆stica (similar al propuesto [aqu铆 con SVM](https://github.com/mmcuri/ds_handson/blob/master/Telecom_Churn_Prediction.ipynb)) para predecir la p茅rdida o salida de clientes en una empresa de telecomunicaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIOrnur9K8AJ"
   },
   "source": [
    "## Librer铆as\n",
    "\n",
    "Importamos varias bibliotecas y m贸dulos 煤tiles para el an谩lisis de datos y el aprendizaje autom谩tico en Python. A continuaci贸n se describe cada uno de ellos:\n",
    "\n",
    "- `pandas as pd`: Importa la biblioteca Pandas y la renombra como \"pd\". Pandas es una biblioteca popular utilizada para la manipulaci贸n y an谩lisis de datos en Python.\n",
    "\n",
    "- `numpy as np`: Importa la biblioteca NumPy y la renombra como \"np\". NumPy es una biblioteca de Python utilizada para realizar operaciones matem谩ticas en matrices y vectores.\n",
    "\n",
    "- `matplotlib.pyplot as plt`: Importa la biblioteca Matplotlib y el m贸dulo pyplot y lo renombra como \"plt\". Matplotlib es una biblioteca utilizada para la visualizaci贸n de datos en Python.\n",
    "\n",
    "- `from sklearn.metrics import classification_report`: Importa la funci贸n classification_report desde el m贸dulo metrics de la biblioteca scikit-learn. classification_report es una funci贸n que calcula y muestra un informe de clasificaci贸n detallado para un modelo de clasificaci贸n.\n",
    "\n",
    "- `from sklearn.metrics import confusion_matrix`: Importa la funci贸n confusion_matrix desde el m贸dulo metrics de la biblioteca scikit-learn. confusion_matrix es una funci贸n que calcula y muestra la matriz de confusi贸n para un modelo de clasificaci贸n.\n",
    "\n",
    "- `from sklearn.metrics import accuracy_score`: Importa la funci贸n accuracy_score desde el m贸dulo metrics de la biblioteca scikit-learn. accuracy_score es una funci贸n que calcula y muestra la precisi贸n de un modelo de clasificaci贸n.\n",
    "\n",
    "- `from sklearn.metrics import roc_auc_score`: Importa la funci贸n roc_auc_score desde el m贸dulo metrics de la biblioteca scikit-learn. roc_auc_score es una funci贸n que calcula el 谩rea bajo la curva ROC (AUC) para un modelo de clasificaci贸n.\n",
    "\n",
    "- `from sklearn.preprocessing import StandardScaler, LabelEncoder`: Importa las clases StandardScaler y LabelEncoder desde el m贸dulo preprocessing de la biblioteca scikit-learn. StandardScaler es una clase utilizada para estandarizar los datos y LabelEncoder es una clase utilizada para codificar las etiquetas de clase en n煤meros enteros.\n",
    "\n",
    "- `from sklearn.model_selection import train_test_split`: Importa la funci贸n train_test_split desde el m贸dulo model_selection de la biblioteca scikit-learn. train_test_split es una funci贸n que divide los datos en conjuntos de entrenamiento y prueba para su uso en el modelado predictivo.\n",
    "\n",
    "En resumen, este c贸digo importa varias bibliotecas y m贸dulos que son 煤tiles para el an谩lisis de datos y el aprendizaje autom谩tico en Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oEkDizrIK-kH",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:34:32.552501Z",
     "start_time": "2025-12-09T03:34:32.543089Z"
    }
   },
   "source": [
    "# importing libraries\n",
    "import pandas as pd #excel sofisticado\n",
    "import numpy as np #matlab\n",
    "import matplotlib.pyplot as plt #plots\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ssl\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HVmpIxQWT4Y"
   },
   "source": [
    "## Base de datos\n",
    "\n",
    "Este conjunto de datos contiene un total de 7043 clientes y 21 caracter铆sticas de los mismos. De las entradas, 5174 son clientes activos y 1869 son clientes que la empresa ha perdido. Observe que el conjunto de datos est谩 desbalanceado pues por cada cliente perdido existe casi 3 clientes activos. La variable de salida para nuestro modelo de machine learning ser谩 `Churn`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oQ4bNy7udtEE",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:34:39.637263Z",
     "start_time": "2025-12-09T03:34:34.170740Z"
    }
   },
   "source": [
    "# importamos dataset\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/mtgca/datasets_public/main/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "#print(df)\n",
    "# vemos las primeras 5 filas\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdmRQpzoL7Ts"
   },
   "source": [
    "### *Detalles de la base de datos*\n",
    "\n",
    "*\t`customerID` - Custumer unique identifier\n",
    "*\t`gender` - Customer gender - ['Female' 'Male']\n",
    "*\t`SeniorCitizen` - Elderly or retired person, a senior citizen is someone who has at least attained the age of 60 of 65 years\n",
    "*\t`Partner` - - ['No' 'Yes']\n",
    "*\t`Dependents` - If customer has dependents - ['No' 'Yes']\n",
    "*\t`Tenure` - Customer lifespan (in months)\n",
    "*\t`PhoneService` - - ['No' 'Yes']\n",
    "*\t`MultipleLines` - - ['No' 'No phone service' 'Yes']\n",
    "*\t`InternetService` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`OnlineSecurity` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`OnlineBackup` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`DeviceProtection` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`TechSupport` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`StreamingTV` - - ['No' 'No internet service' 'Yes']\n",
    "*\t`StreamingMovies` -  - ['No' 'No internet service' 'Yes']\n",
    "*\t`Contract` - Type of contract - ['Month-to-month' 'One year' 'Two year']\n",
    "*\t`PaperlessBilling` - - ['No' 'Yes']\n",
    "*\t`PaymentMethod` - payment method - ['Bank transfer (automatic)', 'Credit card (automatic)', 'Electronic check', 'Mailed check']\n",
    "*\t`MonthlyCharges` - Monthly Recurring Charges\n",
    "*\t`TotalCharges` - Life time value\n",
    "*\t`Churn` - Churn value, the targer vector - ['No' 'Yes']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eysbDSFF_365"
   },
   "source": [
    "### *Limpieza del Dataset*\n",
    "\n",
    "El c贸digo presenta una serie de operaciones de preprocesamiento de datos en una base de datos que contiene informaci贸n sobre clientes de una compa帽铆a, incluyendo su g茅nero, edad, servicios contratados, pagos realizados, entre otros.\n",
    "\n",
    "En primer lugar, se define la funci贸n get_df_size para imprimir el n煤mero de atributos y entradas de la base de datos.\n",
    "\n",
    "Luego, se reemplazan los valores en blanco por NaN para facilitar el manejo de valores faltantes en la base de datos.\n",
    "\n",
    "A continuaci贸n, se reemplazan los valores faltantes en la columna 'TotalCharges' por la mediana de esa columna y se convierte esa columna al tipo num茅rico.\n",
    "\n",
    "Despu茅s, se elimina la columna 'customerID' ya que no es una caracter铆stica relevante.\n",
    "\n",
    "A continuaci贸n, se codifican las caracter铆sticas binarias en 0's y 1's usando LabelEncoder y se imprimen las categor铆as correspondientes a cada una de estas caracter铆sticas.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ue0r1_yYUOyt",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:34:43.023922Z",
     "start_time": "2025-12-09T03:34:42.960429Z"
    }
   },
   "source": [
    "def get_df_size(df, header='Dataset dimensions'):\n",
    "  print(header,\n",
    "        '\\n# Attributes: ', df.shape[1],\n",
    "        '\\n# Entries: ', df.shape[0],'\\n')\n",
    "\n",
    "get_df_size(df)\n",
    "\n",
    "#df.info()\n",
    "\n",
    "# reemplaza valores en blanco por NaN\n",
    "df_clean = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# reemplaza valores faltantes en TotalCharges por la mediana de TotalCharges.\n",
    "#total_charges_median = df_clean.TotalCharges.median()\n",
    "\n",
    "# **Change 1: Convert 'TotalCharges' to numeric before calculating median**\n",
    "df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "\n",
    "# reemplaza valores faltantes en TotalCharges por la mediana de TotalCharges.\n",
    "total_charges_median = df_clean.TotalCharges.median()\n",
    "\n",
    "\n",
    "df_clean['TotalCharges'].fillna(total_charges_median, inplace=True)\n",
    "df_clean['TotalCharges'] = df_clean['TotalCharges'].apply(pd.to_numeric)\n",
    "\n",
    "#CustomerID lo retiramos porque no es una caracter铆stica\n",
    "df_clean = df_clean.drop('customerID', axis=1)\n",
    "df_clean.describe()\n",
    "\n",
    "print(\"Churn No Instances: \", df_clean[df_clean['Churn'] == 'No'].shape[0])\n",
    "print(\"Churn Yes Instances: \", df_clean[df_clean['Churn'] == 'Yes'].shape[0])\n",
    "\n",
    "binary_feat = df_clean.nunique()[df_clean.nunique() == 2].keys().tolist()\n",
    "numeric_feat = [col for col in df_clean.select_dtypes(['float','int']).columns.tolist() if col not in binary_feat]\n",
    "categorical_feat = [ col for col in df_clean.select_dtypes('object').columns.to_list() if col not in binary_feat + numeric_feat ]\n",
    "df_proc = df_clean.copy()\n",
    "#Etiquetas para caracter铆sticas binarias\n",
    "le = LabelEncoder()\n",
    "for i in binary_feat:\n",
    "  df_proc[i] = le.fit_transform(df_proc[i])\n",
    "  print(i, '\\n', np.unique(df_proc[i].values))\n",
    "#Dummy variables\n",
    "df_proc = pd.get_dummies(df_proc, columns=categorical_feat)\n",
    "get_df_size(df, header='Original dataset:')\n",
    "get_df_size(df_proc, header='Processed dataset:')\n",
    "df_proc.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions \n",
      "# Attributes:  21 \n",
      "# Entries:  7043 \n",
      "\n",
      "Churn No Instances:  5174\n",
      "Churn Yes Instances:  1869\n",
      "gender \n",
      " [0 1]\n",
      "SeniorCitizen \n",
      " [0 1]\n",
      "Partner \n",
      " [0 1]\n",
      "Dependents \n",
      " [0 1]\n",
      "PhoneService \n",
      " [0 1]\n",
      "PaperlessBilling \n",
      " [0 1]\n",
      "Churn \n",
      " [0 1]\n",
      "Original dataset: \n",
      "# Attributes:  21 \n",
      "# Entries:  7043 \n",
      "\n",
      "Processed dataset: \n",
      "# Attributes:  41 \n",
      "# Entries:  7043 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/xn60pc294nxddkrtt83tsvdh0000gn/T/ipykernel_14419/3018322231.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean['TotalCharges'].fillna(total_charges_median, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       0              0        1           0       1             0   \n",
       "1       1              0        0           0      34             1   \n",
       "2       1              0        0           0       2             1   \n",
       "3       1              0        0           0      45             0   \n",
       "4       0              0        0           0       2             1   \n",
       "\n",
       "   PaperlessBilling  MonthlyCharges  TotalCharges  Churn  ...  \\\n",
       "0                 1           29.85         29.85      0  ...   \n",
       "1                 0           56.95       1889.50      0  ...   \n",
       "2                 1           53.85        108.15      1  ...   \n",
       "3                 0           42.30       1840.75      0  ...   \n",
       "4                 1           70.70        151.65      1  ...   \n",
       "\n",
       "   StreamingMovies_No  StreamingMovies_No internet service  \\\n",
       "0                True                                False   \n",
       "1                True                                False   \n",
       "2                True                                False   \n",
       "3                True                                False   \n",
       "4                True                                False   \n",
       "\n",
       "   StreamingMovies_Yes  Contract_Month-to-month  Contract_One year  \\\n",
       "0                False                     True              False   \n",
       "1                False                    False               True   \n",
       "2                False                     True              False   \n",
       "3                False                    False               True   \n",
       "4                False                     True              False   \n",
       "\n",
       "   Contract_Two year  PaymentMethod_Bank transfer (automatic)  \\\n",
       "0              False                                    False   \n",
       "1              False                                    False   \n",
       "2              False                                    False   \n",
       "3              False                                     True   \n",
       "4              False                                    False   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                  False                            True   \n",
       "1                                  False                           False   \n",
       "2                                  False                           False   \n",
       "3                                  False                           False   \n",
       "4                                  False                            True   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                       False  \n",
       "1                        True  \n",
       "2                        True  \n",
       "3                       False  \n",
       "4                       False  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <th>StreamingMovies_No internet service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6O3SzEbhBTP"
   },
   "source": [
    "### *Divisi贸n en conjunto de entrenamiento y test*\n",
    "\n",
    "En el c贸digo, se divide el conjunto de datos df_proc en caracter铆sticas y variable objetivo X e y, respectivamente. Luego, se realiza una divisi贸n de los datos en conjuntos de entrenamiento y prueba utilizando la funci贸n train_test_split de scikit-learn. Los conjuntos de entrenamiento y prueba se almacenan en X_train, X_test, y_train y y_test. La divisi贸n se realiza de manera estratificada para asegurar que la proporci贸n de instancias positivas y negativas en la variable objetivo se mantenga en ambos conjuntos. Se utiliza una proporci贸n de 80/20 para los conjuntos de entrenamiento y prueba, respectivamente, y se fija una semilla aleatoria (random_state) en 42 para asegurar que los resultados sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xcqRX5MK0zHy",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:35:05.610273Z",
     "start_time": "2025-12-09T03:35:05.600334Z"
    }
   },
   "source": [
    "# dividimos df_proc en caracter铆sticas y salida\n",
    "X=df_proc.drop('Churn', axis=1) #features\n",
    "y=df_proc['Churn'] #output, target\n",
    "\n",
    "# Dividimos el conjunto de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1dzetBB_h2-"
   },
   "source": [
    "### *Balanceo de datos*\n",
    "\n",
    "Este c贸digo realiza el submuestreo (undersampling) de un conjunto de datos desbalanceado en t茅rminos de la variable objetivo. El submuestreo se utiliza para abordar el problema del desequilibrio de clases en el conjunto de datos, donde una o varias clases tienen muchas menos observaciones que las otras clases. En este caso, el modelo de aprendizaje autom谩tico puede estar sesgado hacia la clase mayoritaria, lo que puede resultar en un rendimiento deficiente en la clasificaci贸n de la clase minoritaria.\n",
    "\n",
    "El submuestreo implica reducir el n煤mero de observaciones en la clase mayoritaria para equilibrar la distribuci贸n de las clases en el conjunto de datos. Esto puede mejorar el rendimiento del modelo en la clasificaci贸n de la clase minoritaria y reducir el sesgo hacia la clase mayoritaria.\n",
    "\n",
    "La biblioteca imblearn se utiliza para realizar el submuestreo, y en este caso se importa la clase RandomUnderSampler. El objeto RandomUnderSampler se inicializa con random_state=1, lo que garantiza que los resultados ser谩n reproducibles.\n",
    "\n",
    "Luego, el submuestreo se realiza en el conjunto de entrenamiento (X_train, y_train) mediante el m茅todo fit_resample del objeto rus. Los datos submuestreados se almacenan en X_train_rus y y_train_rus.\n",
    "\n",
    "Para evaluar el efecto del submuestreo, se utiliza la funci贸n get_df_size, que devuelve el tama帽o del conjunto de datos. Primero se imprime el tama帽o del conjunto de entrenamiento original (X_train, y_train) antes del submuestreo, y luego se imprime el tama帽o del conjunto submuestreado (X_train_rus, y_train_rus) despu茅s de aplicar el submuestreo.\n",
    "\n",
    "Finalmente, se utiliza la funci贸n np.unique para verificar que las categor铆as de la variable objetivo (y_train_rus) est茅n balanceadas. La funci贸n devuelve una tupla que contiene las categor铆as 煤nicas y el n煤mero de instancias en cada categor铆a. Al utilizar return_counts=True, se garantiza que se devuelvan los recuentos de las categor铆as."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L-gWnlmK7TC1",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:35:17.800239Z",
     "start_time": "2025-12-09T03:35:16.515597Z"
    }
   },
   "source": "!pip install imblearn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\r\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.13/site-packages (from imblearn) (0.13.0)\r\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.6.1)\r\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (0.1.3)\r\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (3.5.0)\r\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Installing collected packages: imblearn\r\n",
      "Successfully installed imblearn-0.0\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WL_1nk9KAJeu",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:35:20.862671Z",
     "start_time": "2025-12-09T03:35:20.600336Z"
    }
   },
   "source": [
    "# submuestreo -> under sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_train_undersampled, y_train_undersampled = rus.fit_resample(X_train, y_train)\n",
    "get_df_size(X_train, header='Before balancing:')\n",
    "get_df_size(X_train_undersampled, header='After balancing:')\n",
    "\n",
    "# verificamos que las categorias est茅n balanceadas\n",
    "np.unique(y_train_undersampled, return_counts=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing: \n",
      "# Attributes:  40 \n",
      "# Entries:  5634 \n",
      "\n",
      "After balancing: \n",
      "# Attributes:  40 \n",
      "# Entries:  2990 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1495, 1495]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WS6tkPN6shIN"
   },
   "source": [
    "## Modelo de Machine Learning\n",
    "\n",
    "Este c贸digo construye un modelo de regresi贸n log铆stica para un conjunto de datos y lo eval煤a en un conjunto de datos de prueba y de entrenamiento.\n",
    "\n",
    "Primero, se define una tuber铆a (pipeline) que encadena tres pasos:\n",
    "\n",
    "PolynomialFeatures(degree=2): Crea una matriz de caracter铆sticas polin贸micas de grado 2 a partir de las caracter铆sticas originales.\n",
    "StandardScaler(): Estandariza las caracter铆sticas.\n",
    "LogisticRegression(max_iter=20000, penalty='l2', C=1/lambda_value): Ajusta un modelo de regresi贸n log铆stica a los datos, utilizando una regularizaci贸n L2 (Ridge) y un par谩metro de regularizaci贸n C inversamente proporcional a lambda_value.\n",
    "Luego, el modelo se entrena en un conjunto de datos de entrenamiento (X_train_undersampled e y_train_undersampled) utilizando el m茅todo fit.\n",
    "\n",
    "A continuaci贸n, el modelo se eval煤a en un conjunto de datos de prueba (X_test e y_test). Las predicciones se obtienen con el m茅todo predict y se calcula la precisi贸n (accuracy) utilizando metrics.accuracy_score. La precisi贸n en el conjunto de datos de prueba se almacena en la variable acc_test y se imprime en pantalla.\n",
    "\n",
    "Finalmente, se eval煤a el modelo en el conjunto de datos de entrenamiento (X_train_undersampled e y_train_undersampled) y se almacena la precisi贸n en la variable acc_train, que tambi茅n se imprime en pantalla."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uE2CTmLsEWlC",
    "ExecuteTime": {
     "end_time": "2025-12-09T03:35:24.215257Z",
     "start_time": "2025-12-09T03:35:23.844552Z"
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "model_logreg =  Pipeline([\n",
    "                ('polynomial_features', PolynomialFeatures(degree=2)), #no cambiar\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('logistic_regression', LogisticRegression(max_iter=2000, penalty='l2'))\n",
    " ])\n",
    "\n",
    "# training\n",
    "model_logreg.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# evaluation on test set\n",
    "pred_test = model_logreg.predict(X_test)\n",
    "f1score = metrics.f1_score(y_test, pred_test)\n",
    "acc = metrics.accuracy_score(y_test, pred_test)\n",
    "preci = metrics.precision_score(y_test, pred_test)\n",
    "recall = metrics.recall_score(y_test, pred_test)\n",
    "\n",
    "print(\"Para el modelo NO optimizado, m茅tricas en el conjunto de test: recall = \", recall, \", F1 = \", f1score, \", acc = \", acc, \", precision = \", preci, )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo NO optimizado, m茅tricas en el conjunto de test: recall =  0.7700534759358288 , F1 =  0.6056782334384858 , acc =  0.7338537970191625 , precision =  0.49913344887348354\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBJHeay7mFFA"
   },
   "source": [
    "### Optimizaci贸n de Hiperpar谩metros Logistic Regression con kfold CV sin PCA\n",
    "\n",
    "Usamos k-fold cross-validation (ver `GridSearchCV` y  `StratifiedKFold`) para optimizar los siguientes hiperpar谩metros de Logistic Regression en el conjunto de entrenamiento balanceado (`X_train_undersampled`, `y_train_undersampled`):\n",
    "\n",
    "1. lambda: par谩metro de regularizaci贸n que es inverso al valor de lambda estudiado en clase. Se utilizar谩 los siguientes valores [ 1e-4, 1e-3, 1e-2, 0.1]\n",
    "2. penalty: tipo de regularizaci贸n para evitar overfitting. Se utilizar谩 'l2' y 'l1'.\n",
    "\n",
    "Para la optimizaci贸n de hiperpar谩metros utilizamos como m茅trica al recall.\n",
    "\n",
    "Una vez optimizados los hiperpar谩metros, reentrenamos el clasificador con los mejores hiperpar谩metros encontrados. Finalmente, evaluamos este 煤ltimo clasificador en el conjunto de test `X_test`, `y_test`.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W1gaoe7clx2S",
    "ExecuteTime": {
     "end_time": "2025-12-09T04:05:46.164515Z",
     "start_time": "2025-12-09T03:53:49.069969Z"
    }
   },
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#optimizaci贸n\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=45) #para nsplits=5 demora 35 min approx en google colab.\n",
    "\n",
    "# pipeline\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('polynomial_features', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_reg', LogisticRegression(max_iter=10000, solver='saga'))\n",
    "])\n",
    "\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 0.1]\n",
    "C_range = [1 / (lambda_value) for lambda_value in lambda_range] #transforma al inverso de lambda\n",
    "param_grid = {'logistic_reg__C': C_range,\n",
    "              'logistic_reg__penalty': ['l2', 'l1']}\n",
    "\n",
    "search = GridSearchCV(pipeline_log_reg,\n",
    "                      param_grid, scoring='recall',\n",
    "                      cv=kfold,\n",
    "                      verbose=4,\n",
    "                      n_jobs=1) #use single process (Windows compatible)\n",
    "result = search.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "print(f'Mejor recall en el conj. de validaci贸n: {result.best_score_} para {result.best_params_}')\n",
    "\n",
    "#reentreno con mejores\n",
    "pipeline_log_reg.set_params(logistic_reg__C=result.best_params_['logistic_reg__C'],\n",
    "                       logistic_reg__penalty=result.best_params_['logistic_reg__penalty'],)\n",
    "pipeline_log_reg.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "#evaluamos en el conjunto de test\n",
    "pred_test = pipeline_log_reg.predict(X_test)\n",
    "f1score = metrics.f1_score(y_test, pred_test)\n",
    "acc = metrics.accuracy_score(y_test, pred_test)\n",
    "preci = metrics.precision_score(y_test, pred_test)\n",
    "recall = metrics.recall_score(y_test, pred_test)\n",
    "\n",
    "print(\"Para el modelo optimizado, m茅tricas en el conjunto de test: recall = \", recall, \", F1 = \", f1score, \", acc = \", acc, \", precision = \", preci, )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.734 total time=  34.0s\n",
      "[CV 2/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.746 total time=  15.5s\n",
      "[CV 1/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.734 total time= 1.1min\n",
      "[CV 2/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.746 total time=  30.0s\n",
      "[CV 1/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.734 total time=  34.2s\n",
      "[CV 2/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.746 total time=  15.7s\n",
      "[CV 1/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.734 total time= 1.1min\n",
      "[CV 2/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.746 total time=  30.2s\n",
      "[CV 1/2] END logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.734 total time=  33.2s\n",
      "[CV 2/2] END logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.746 total time=  14.9s\n",
      "[CV 1/2] END logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.735 total time= 1.1min\n",
      "[CV 2/2] END logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.746 total time=  27.6s\n",
      "[CV 1/2] END logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.736 total time=  26.3s\n",
      "[CV 2/2] END logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.747 total time=  12.9s\n",
      "[CV 1/2] END logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.743 total time=  43.6s\n",
      "[CV 2/2] END logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.749 total time=  22.4s\n",
      "Mejor recall en el conj. de validaci贸n: 0.7458174945772394 para {'logistic_reg__C': 10.0, 'logistic_reg__penalty': 'l1'}\n",
      "Para el modelo optimizado, m茅tricas en el conjunto de test: recall =  0.767379679144385 , F1 =  0.6054852320675106 , acc =  0.7345635202271115 , precision =  0.5\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHQ7UQiP64w4"
   },
   "source": [
    "### Optimizaci贸n de hiperpar谩metros Logistic Regression con PCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QwHMW9EV7AXF",
    "ExecuteTime": {
     "end_time": "2025-12-09T04:06:30.088725Z",
     "start_time": "2025-12-09T04:06:22.250322Z"
    }
   },
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "#optimizaci贸n\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=45) #para nsplits=5 demora 35 min approx en google colab.\n",
    "\n",
    "# pipeline\n",
    "pipeline_log_reg_pca = Pipeline([\n",
    "     ('polynomial_features', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()), #zscore\n",
    "    ('pca', PCA(n_components=0.95)), #comprime: 95% variance retained (information retained)\n",
    "    ('logistic_reg', LogisticRegression(max_iter=20000, solver='saga'))\n",
    "])\n",
    "\n",
    "lambda_range = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1]\n",
    "C_range = [1 / (lambda_value) for lambda_value in lambda_range] #transforma al inverso de lambda\n",
    "param_grid = {'logistic_reg__C': C_range,\n",
    "              'logistic_reg__penalty': ['l2', 'l1']}\n",
    "\n",
    "search = GridSearchCV(pipeline_log_reg_pca, param_grid, scoring='recall', cv=kfold, verbose=4, n_jobs=1)\n",
    "result = search.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "print(f'Mejor recall en el conj. de validaci贸n: {result.best_score_} para {result.best_params_}')\n",
    "\n",
    "#reentreno con mejores\n",
    "pipeline_log_reg_pca.set_params(logistic_reg__C=result.best_params_['logistic_reg__C'],\n",
    "                       logistic_reg__penalty=result.best_params_['logistic_reg__penalty'],)\n",
    "pipeline_log_reg_pca.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "#evaluamos en el conjunto de test\n",
    "pred_test = pipeline_log_reg_pca.predict(X_test)\n",
    "f1score = metrics.f1_score(y_test, pred_test)\n",
    "acc = metrics.accuracy_score(y_test, pred_test)\n",
    "preci = metrics.precision_score(y_test, pred_test)\n",
    "recall = metrics.recall_score(y_test, pred_test)\n",
    "\n",
    "print(\"Para el modelo optimizado, m茅tricas en el conjunto de test: recall = \", recall, \", F1 = \", f1score, \", acc = \", acc, \", precision = \", preci, )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
      "[CV 1/2] END logistic_reg__C=10000000.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.2s\n",
      "[CV 2/2] END logistic_reg__C=10000000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=10000000.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=10000000.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=1000000.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=1000000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=1000000.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=1000000.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.790 total time=   0.2s\n",
      "[CV 2/2] END logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 1/2] END logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.790 total time=   0.3s\n",
      "[CV 2/2] END logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.3s\n",
      "Mejor recall en el conj. de validaci贸n: 0.7772659264509016 para {'logistic_reg__C': 10000000.0, 'logistic_reg__penalty': 'l2'}\n",
      "Para el modelo optimizado, m茅tricas en el conjunto de test: recall =  0.7620320855614974 , F1 =  0.6038135593220338 , acc =  0.7345635202271115 , precision =  0.5\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiejT8MCHQ3D"
   },
   "source": [
    "###  **Actividad 1: An谩lisis de resultados: Optimizaci贸n de hiperpar谩metros Regresi贸n Log铆stica**\n",
    "\n",
    "Ejecute el c贸digo de esta notebook y analice los siguientes casos:\n",
    "\n",
    "1. Logistic Regression sin PCA\n",
    "2. Logistic Regression con PCA\n",
    "\n",
    "\n",
    "Comente sus resultados analizando los valores de recall, f1 score, accuracy y precisi贸n en el conjunto de test.\n",
    "\n",
    "- Recall SIN PCA : 0.767379679144385 , F1 =  0.6054852320675106 , acc =  0.7345635202271115 , precision =  0.5\n",
    "- Recall PCA: 0.7620320855614974 , F1 =  0.6038135593220338 , acc =  0.7345635202271115 , precision =  0.5\n",
    "\n",
    "Cu谩l es mejor en t茅rminos de recall?\n",
    "- SIN PCA gana por un margen insignificante de 0.54\n",
    "\n",
    "Cu谩l demora menos en entrenar? Vale la pena usar PCA? Considere si el resultado sin PCA justifica el entrenamiento m谩s largo.\n",
    "- El que no tiene PCA demora mucho mas,vale totalmente la pena usar con PCA por el tema de tiempo ya que no demora casi nada comparado con el que no tiene PCA, si justificamos el entrenamiento mas largo Si el negocio es extremadamente sensible a capturar cada cliente, elegir铆a sin PCA por su 0.54% adicional.\n",
    "\n",
    "Por qu茅 cree que el recall es una m茅trica m谩s adecuada para este problema? Tip: El recall est谩 relacionado a los falsos negativos. Analice por qu茅 es importante disminuir los falsos negativos en el churn.\n",
    "\n",
    "- Falsos Negativos = Clientes perdidos para siempre\n",
    "No podemos hacer oferta de retenci贸n\n",
    "Costo de reacquisition es 5x m谩s caro\n",
    "- Falsos Positivos = Ofertas baratas\n",
    "\n",
    "Ofertamos descuento a quien se quedar铆a\n",
    "Bajo impacto econ贸mico\n",
    "- En churn, evitar FN es m谩s importante que evitar FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWpCJ-BxR7V-"
   },
   "source": [
    "#  **Actividad**: Feature selection y repeated k fold cv\n",
    "\n",
    "Crear un pipeline con las siguientes etapas usando **repeated kfold cv:**\n",
    "\n",
    "1. **Feature selection** (m茅todo filter)\n",
    "2. Polynomial features con degree 2\n",
    "3. Scaler\n",
    "4. PCA\n",
    "5. Logistic Regression\n",
    "\n",
    "Optimizar los param. de logistic regression.\n",
    "Evaluar en el conjunto de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L6GcZd7y7TC4",
    "ExecuteTime": {
     "end_time": "2025-12-09T04:08:01.330546Z",
     "start_time": "2025-12-09T04:06:39.559788Z"
    }
   },
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE SELECTION WITH REPEATED STRATIFIED K-FOLD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SELECTION + REPEATED K-FOLD CV + LOGISTIC REGRESSION PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define Repeated Stratified K-Fold (3 splits, 2 repeats)\n",
    "rskfold = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=42)\n",
    "\n",
    "# Pipeline allowing different feature selection techniques\n",
    "# We'll search over multiple alternatives:\n",
    "# - Filter: SelectKBest with f_classif\n",
    "# - Filter: SelectKBest with mutual_info_classif\n",
    "# - Embedded: SelectFromModel with L1-regularized Logistic Regression (sparsity)\n",
    "pipeline_fs = Pipeline([\n",
    "    ('feature_selection', 'passthrough'),  # will be set via GridSearchCV\n",
    "    ('polynomial_features', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('logistic_reg', LogisticRegression(max_iter=20000, solver='saga'))\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter optimization\n",
    "lambda_range = [1e-5, 1e-4, 1e-3, 1e-2, 0.1]\n",
    "C_range = [1 / lambda_value for lambda_value in lambda_range]\n",
    "\n",
    "# Keep grid modest to control runtime (Windows, single job)\n",
    "param_grid_fs = [\n",
    "    {\n",
    "        'feature_selection': [SelectKBest(score_func=f_classif, k=15)],\n",
    "        'logistic_reg__C': C_range,\n",
    "        'logistic_reg__penalty': ['l2', 'l1']\n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectKBest(score_func=mutual_info_classif, k=15)],\n",
    "        'logistic_reg__C': C_range,\n",
    "        'logistic_reg__penalty': ['l2', 'l1']\n",
    "    },\n",
    "    {\n",
    "        # Embedded method: L1 selects features with non-zero coefficients\n",
    "        'feature_selection': [\n",
    "            SelectFromModel(\n",
    "                LogisticRegression(\n",
    "                    penalty='l1', solver='saga', C=1.0, max_iter=20000, n_jobs=None\n",
    "                ),\n",
    "                max_features=20, threshold='median'\n",
    "            )\n",
    "        ],\n",
    "        'logistic_reg__C': C_range,\n",
    "        'logistic_reg__penalty': ['l2', 'l1']\n",
    "    }\n",
    "]\n",
    "\n",
    "# GridSearchCV with Repeated Stratified K-Fold\n",
    "print(\"\\nRunning GridSearchCV with Repeated Stratified K-Fold (3 splits, 2 repeats)...\")\n",
    "# Compute total combinations across all sub-grids\n",
    "total_hparams = sum(len(grid['logistic_reg__C']) * len(grid['logistic_reg__penalty']) for grid in param_grid_fs)\n",
    "total_models = total_hparams * rskfold.get_n_splits()\n",
    "print(f\"Total combinations to evaluate: {total_hparams} hyperparameters  {rskfold.get_n_splits()} folds = {total_models} models\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "search_fs = GridSearchCV(\n",
    "    pipeline_fs,\n",
    "    param_grid_fs,\n",
    "    scoring='recall',\n",
    "    cv=rskfold,\n",
    "    verbose=3,\n",
    "    n_jobs=1  # Windows compatible\n",
    ")\n",
    "\n",
    "result_fs = search_fs.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n GridSearchCV completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"\\nBest recall on validation set: {result_fs.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {result_fs.best_params_}\")\n",
    "print(f\"Selected feature selection technique: {type(result_fs.best_params_['feature_selection']).__name__}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "# Refit pipeline with best parameters (including selected feature selector)\n",
    "pipeline_fs.set_params(\n",
    "    feature_selection=result_fs.best_params_['feature_selection'],\n",
    "    logistic_reg__C=result_fs.best_params_['logistic_reg__C'],\n",
    "    logistic_reg__penalty=result_fs.best_params_['logistic_reg__penalty']\n",
    ")\n",
    "pipeline_fs.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Make predictions on test set\n",
    "pred_test_fs = pipeline_fs.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "f1_fs = metrics.f1_score(y_test, pred_test_fs)\n",
    "acc_fs = metrics.accuracy_score(y_test, pred_test_fs)\n",
    "prec_fs = metrics.precision_score(y_test, pred_test_fs)\n",
    "rec_fs = metrics.recall_score(y_test, pred_test_fs)\n",
    "roc_auc_fs = metrics.roc_auc_score(y_test, pipeline_fs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SET RESULTS - Pipeline with Feature Selection + Repeated K-Fold CV\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Recall:    {rec_fs:.4f}\")\n",
    "print(f\"Precision: {prec_fs:.4f}\")\n",
    "print(f\"F1 Score:  {f1_fs:.4f}\")\n",
    "print(f\"Accuracy:  {acc_fs:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_fs:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "# Get the feature selector from the pipeline\n",
    "feature_selector = pipeline_fs.named_steps['feature_selection']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if hasattr(feature_selector, 'get_support'):\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "    selected_feature_names = X_train_undersampled.columns[selected_feature_indices]\n",
    "\n",
    "    if isinstance(feature_selector, SelectKBest):\n",
    "        title = (\n",
    "            \"SELECTED FEATURES (Top k by f_classif)\"\n",
    "            if feature_selector.score_func == f_classif\n",
    "            else \"SELECTED FEATURES (Top k by mutual_info_classif)\"\n",
    "        )\n",
    "        print(title)\n",
    "        # Scores are aligned with original columns\n",
    "        if hasattr(feature_selector, 'scores_') and feature_selector.scores_ is not None:\n",
    "            feature_scores = feature_selector.scores_[selected_feature_indices]\n",
    "            sorted_idx = np.argsort(feature_scores)[::-1]\n",
    "            for i, idx in enumerate(sorted_idx, 1):\n",
    "                feature_name = selected_feature_names[idx]\n",
    "                score = feature_scores[idx]\n",
    "                print(f\"{i:2d}. {feature_name:30s} - Score: {score:.4f}\")\n",
    "        else:\n",
    "            # mutual_info_classif stores scores_ too; fallback if missing\n",
    "            print(list(selected_feature_names))\n",
    "    elif isinstance(feature_selector, SelectFromModel):\n",
    "        print(\"SELECTED FEATURES (SelectFromModel - L1 LogisticRegression)\")\n",
    "        print(list(selected_feature_names))\n",
    "        # Optionally show absolute coefficient magnitudes for selected features\n",
    "        try:\n",
    "            est = feature_selector.estimator_\n",
    "            coefs = np.abs(est.coef_).ravel()\n",
    "            # Map back to original features\n",
    "            all_names = X_train_undersampled.columns\n",
    "            coef_map = {name: coef for name, coef in zip(all_names, coefs)}\n",
    "            selected_pairs = [(name, coef_map[name]) for name in selected_feature_names]\n",
    "            selected_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "            for i, (name, val) in enumerate(selected_pairs, 1):\n",
    "                print(f\"{i:2d}. {name:30s} - |coef|: {val:.4f}\")\n",
    "        except Exception as _:\n",
    "            pass\n",
    "else:\n",
    "    print(\"No feature selection applied or selector does not support get_support().\")\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSIFICATION REPORT AND CONFUSION MATRIX\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(metrics.classification_report(y_test, pred_test_fs))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, pred_test_fs)\n",
    "print(cm)\n",
    "print(f\"True Negatives:  {cm[0, 0]}\")\n",
    "print(f\"False Positives: {cm[0, 1]}\")\n",
    "print(f\"False Negatives: {cm[1, 0]}\")\n",
    "print(f\"True Positives:  {cm[1, 1]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE SELECTION + REPEATED K-FOLD CV + LOGISTIC REGRESSION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Running GridSearchCV with Repeated Stratified K-Fold (3 splits, 2 repeats)...\n",
      "Total combinations to evaluate: 30 hyperparameters  6 folds = 180 models\n",
      "Fitting 6 folds for each of 30 candidates, totalling 180 fits\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.777 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.803 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.803 total time=   0.0s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.0s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.770 total time=   0.0s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.743 total time=   0.0s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.791 total time=   0.2s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.731 total time=   0.2s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.793 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.774 total time=   0.2s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.761 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.803 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.739 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.771 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.785 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.762 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.763 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.795 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.727 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.791 total time=   0.2s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.2s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.755 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.801 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.727 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.779 total time=   0.2s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.801 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.774 total time=   0.2s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.755 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.797 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.727 total time=   0.2s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.2s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.797 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.770 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.763 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.799 total time=   0.2s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.727 total time=   0.2s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.779 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.783 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.768 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.755 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.791 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.725 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.779 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.789 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.762 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.755 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.789 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.727 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.785 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.785 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.772 total time=   0.2s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.793 total time=   0.2s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.739 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.765 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.785 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.768 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.761 total time=   0.1s\n",
      "[CV 1/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.799 total time=   0.1s\n",
      "[CV 2/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.737 total time=   0.1s\n",
      "[CV 3/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.765 total time=   0.1s\n",
      "[CV 4/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.785 total time=   0.1s\n",
      "[CV 5/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.770 total time=   0.1s\n",
      "[CV 6/6] END feature_selection=SelectKBest(k=15, score_func=<function mutual_info_classif at 0x315b64430>), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.761 total time=   0.2s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l2;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.799 total time=   1.1s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=99999.99999999999, logistic_reg__penalty=l1;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l2;, score=0.769 total time=   1.2s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10000.0, logistic_reg__penalty=l1;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.799 total time=   1.1s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l2;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.799 total time=   1.1s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=1000.0, logistic_reg__penalty=l1;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l2;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.799 total time=   1.1s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=100.0, logistic_reg__penalty=l1;, score=0.769 total time=   1.2s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l2;, score=0.769 total time=   1.1s\n",
      "[CV 1/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.799 total time=   1.2s\n",
      "[CV 2/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.749 total time=   1.1s\n",
      "[CV 3/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.783 total time=   1.2s\n",
      "[CV 4/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.793 total time=   1.1s\n",
      "[CV 5/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.790 total time=   1.2s\n",
      "[CV 6/6] END feature_selection=SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), logistic_reg__C=10.0, logistic_reg__penalty=l1;, score=0.769 total time=   1.1s\n",
      "\n",
      " GridSearchCV completed in 80.32 seconds\n",
      "\n",
      "Best recall on validation set: 0.7806\n",
      "Best parameters: {'feature_selection': SelectFromModel(estimator=LogisticRegression(max_iter=20000, penalty='l1',\n",
      "                                             solver='saga'),\n",
      "                max_features=20, threshold='median'), 'logistic_reg__C': 99999.99999999999, 'logistic_reg__penalty': 'l2'}\n",
      "Selected feature selection technique: SelectFromModel\n",
      "\n",
      "================================================================================\n",
      "TEST SET RESULTS - Pipeline with Feature Selection + Repeated K-Fold CV\n",
      "================================================================================\n",
      "Recall:    0.7861\n",
      "Precision: 0.5017\n",
      "F1 Score:  0.6125\n",
      "Accuracy:  0.7360\n",
      "ROC-AUC:   0.8317\n",
      "\n",
      "================================================================================\n",
      "FEATURE SELECTION SUMMARY\n",
      "================================================================================\n",
      "SELECTED FEATURES (SelectFromModel - L1 LogisticRegression)\n",
      "['tenure', 'PhoneService', 'MonthlyCharges', 'MultipleLines_No', 'InternetService_DSL', 'InternetService_Fiber optic', 'InternetService_No', 'OnlineSecurity_No', 'OnlineSecurity_No internet service', 'OnlineSecurity_Yes', 'OnlineBackup_No internet service', 'DeviceProtection_No internet service', 'TechSupport_No', 'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No internet service', 'StreamingMovies_No internet service', 'Contract_Two year', 'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check']\n",
      " 1. tenure                         - |coef|: 0.0706\n",
      " 2. MonthlyCharges                 - |coef|: 0.0220\n",
      " 3. MultipleLines_No               - |coef|: 0.0051\n",
      " 4. OnlineSecurity_No              - |coef|: 0.0047\n",
      " 5. TechSupport_No                 - |coef|: 0.0046\n",
      " 6. PaymentMethod_Electronic check - |coef|: 0.0045\n",
      " 7. InternetService_Fiber optic    - |coef|: 0.0043\n",
      " 8. OnlineSecurity_Yes             - |coef|: 0.0040\n",
      " 9. InternetService_No             - |coef|: 0.0039\n",
      "10. OnlineSecurity_No internet service - |coef|: 0.0039\n",
      "11. OnlineBackup_No internet service - |coef|: 0.0039\n",
      "12. DeviceProtection_No internet service - |coef|: 0.0039\n",
      "13. TechSupport_No internet service - |coef|: 0.0039\n",
      "14. StreamingTV_No internet service - |coef|: 0.0039\n",
      "15. StreamingMovies_No internet service - |coef|: 0.0039\n",
      "16. TechSupport_Yes                - |coef|: 0.0039\n",
      "17. PhoneService                   - |coef|: 0.0039\n",
      "18. Contract_Two year              - |coef|: 0.0038\n",
      "19. PaymentMethod_Mailed check     - |coef|: 0.0037\n",
      "20. InternetService_DSL            - |coef|: 0.0036\n",
      "\n",
      "================================================================================\n",
      "CLASSIFICATION REPORT\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1035\n",
      "           1       0.50      0.79      0.61       374\n",
      "\n",
      "    accuracy                           0.74      1409\n",
      "   macro avg       0.70      0.75      0.71      1409\n",
      "weighted avg       0.80      0.74      0.75      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[743 292]\n",
      " [ 80 294]]\n",
      "True Negatives:  743\n",
      "False Positives: 292\n",
      "False Negatives: 80\n",
      "True Positives:  294\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KIOrnur9K8AJ",
    "0HVmpIxQWT4Y"
   ],
   "provenance": [
    {
     "file_id": "1lk0cw1bV6B-2y-sF2v2l0fPzAVsBLOcn",
     "timestamp": 1765226166085
    }
   ],
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
